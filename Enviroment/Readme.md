# YOLO11n TensorRT (FP16) on Jetson Orin Nano

Jetson Orin Nano (JetPack 6.x / CUDA 12.6) í™˜ê²½ì—ì„œ YOLO11n ëª¨ë¸ì„ TensorRT FP16 ì—”ì§„ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì‹¤í–‰í•˜ëŠ” ê°€ì´ë“œì…ë‹ˆë‹¤.

## í™˜ê²½ ì‚¬ì–‘

| í•­ëª© | ë‚´ìš© |
|------|------|
| Device | Jetson Orin Nano |
| JetPack | 6.x (L4T R36) |
| CUDA | 12.6 |
| TensorRT | 10.3.0 |
| Python | 3.10.12 |
| PyTorch | 2.5.0a0 (NVIDIA build, CUDA enabled) |
| torchvision | 0.20.0 (source build, CUDA enabled) |

## 1. ì‹œìŠ¤í…œ í™•ì¸

### CUDA í™•ì¸
```bash
nvcc --version
# ì¶œë ¥: Cuda compilation tools, release 12.6, V12.6.68
```

### GPU ìƒíƒœ í™•ì¸
```bash
sudo tegrastats  # Jetson ê¶Œì¥
```

## 2. PyTorch (CUDA Enabled) ì„¤ì¹˜

âš ï¸ Jetsonì—ì„œëŠ” `pip install torch`ë¡œ ì„¤ì¹˜ë˜ëŠ” PyTorchê°€ CPU ì „ìš©ì´ë¯€ë¡œ NVIDIA JetPack ì „ìš© wheelì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

```bash
# ê¸°ì¡´ torch ì œê±°
python3 -m pip uninstall -y torch torchvision torchaudio

# NVIDIA PyTorch wheel ì„¤ì¹˜ (JetPack 6.x / Python 3.10)
python3 -m pip install \
  https://developer.download.nvidia.com/compute/redist/jp/v61/pytorch/torch-2.5.0a0+872d972e41.nv24.08.17622132-cp310-cp310-linux_aarch64.whl
```

### CUDA PyTorch í™•ì¸
```python
import torch
print(torch.__version__)
print(torch.version.cuda)
print(torch.cuda.is_available())
print(torch.cuda.get_device_name(0))
```

## 3. cuSPARSELt ì„¤ì¹˜

PyTorch 2.4+ ë¹Œë“œëŠ” cuSPARSELt ëŸ°íƒ€ì„ì„ ë³„ë„ë¡œ ìš”êµ¬í•©ë‹ˆë‹¤.

```bash
# cuSPARSELt ë‹¤ìš´ë¡œë“œ (CUDA 12.x, aarch64)
wget https://developer.download.nvidia.com/compute/cusparselt/redist/libcusparse_lt/linux-aarch64/libcusparse_lt-linux-aarch64-0.8.1.1_cuda12-archive.tar.xz

# ì••ì¶• í•´ì œ ë° ì„¤ì¹˜
tar -xvf libcusparse_lt-linux-aarch64-0.8.1.1_cuda12-archive.tar.xz
sudo cp libcusparseLt.so* /usr/lib/aarch64-linux-gnu/
sudo ldconfig
```

âš ï¸ `ldconfig: libcusparseLt.so.0 is not a symbolic link` ê²½ê³ ëŠ” ë¬´ì‹œí•´ë„ ë©ë‹ˆë‹¤.

## 4. torchvision ë¹Œë“œ (CUDA Extension í¬í•¨)

### ë¹Œë“œ ì˜ì¡´ì„± ì„¤ì¹˜
```bash
sudo apt-get update
sudo apt-get install -y \
  build-essential cmake git \
  libjpeg-dev zlib1g-dev libpng-dev \
  python3-dev python3-opencv
```

### numpy ë²„ì „ ê³ ì •
```bash
python3 -m pip install "numpy==1.26.1"
```

### torchvision ì†ŒìŠ¤ ë¹Œë“œ
```bash
git clone https://github.com/pytorch/vision torchvision
cd torchvision
git checkout v0.20.0
```

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (Orin Nano = SM 8.7)
```bash
export CUDA_HOME=/usr/local/cuda
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH
export TORCH_CUDA_ARCH_LIST="8.7"
export FORCE_CUDA="1"
```

### ë¹Œë“œ ë° ì„¤ì¹˜
```bash
python3 -m pip uninstall -y torchvision || true
python3 -m pip install -v --no-cache-dir --no-build-isolation .
```

### í™•ì¸
```python
import torch, torchvision
print(torch.__version__)
print(torchvision.__version__)
print(torch.cuda.is_available())
```

## 5. Ultralytics (YOLO11) ì„¤ì¹˜

âš ï¸ Jetsonì—ì„œëŠ” `opencv-python` (pip) ëŒ€ì‹  `python3-opencv` (apt) ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.

```bash
python3 -m pip install ultralytics --no-deps
yolo checks
```

## 6. ONNX Export Dependencies

```bash
python3 -m pip install "onnx>=1.12,<2" "onnxslim>=0.1.71"
```

## 7. YOLO11n â†’ TensorRT FP16 Engine Export

```bash
yolo export model=yolo11n.pt format=engine half=True device=0 imgsz=640
```

### Export ê²°ê³¼
- âœ… ONNX export ì„±ê³µ
- âœ… TensorRT build ì„±ê³µ
- âœ… FP16 engine ìƒì„± ì™„ë£Œ

### ìƒì„±ëœ íŒŒì¼ í™•ì¸
```bash
ls -lh *.engine *.onnx
# yolo11n.onnx (~11 MB)
# yolo11n.engine (~8.4 MB)
```

## 8. TensorRT Engine Inference

### ì´ë¯¸ì§€ ì¶”ë¡ 
```bash
yolo predict model=yolo11n.engine source=sample.jpg device=0
```

### ì‹¤ì‹œê°„ ì¹´ë©”ë¼
```bash
yolo predict model=yolo11n.engine source=0 device=0
```

## 9. Performance Optimization (ì„ íƒì‚¬í•­)

### ì „ë ¥/í´ëŸ­ ê³ ì •
```bash
sudo nvpmodel -m 2
sudo jetson_clocks
```

### ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
```bash
sudo tegrastats
```

## ìµœì¢… ìƒíƒœ

âœ… PyTorch CUDA enabled  
âœ… torchvision CUDA extension enabled  
âœ… ONNX export successful  
âœ… TensorRT FP16 engine generated  
âœ… Real-time inference on Jetson Orin Nano  

ğŸš€ **Environment is ready for real-time Edge AI deployment**
